{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 1. 데이터 준비"
      ],
      "metadata": {
        "id": "s-7Ugsf_b02_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "trVN4dXdjCb7"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_data = pd.read_csv('/content/x_data.csv', index_col=0)"
      ],
      "metadata": {
        "id": "rNpmlheOjFaS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle"
      ],
      "metadata": {
        "id": "gE4-UYxkjMdG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(r'/content/data_y.pkl', 'rb') as f:\n",
        "    y_data = pickle.load(f)"
      ],
      "metadata": {
        "id": "WoRFsky2jRz5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 분포\n",
        "y_data.count(0), y_data.count(1), y_data.count(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cq0d_1oY2kzv",
        "outputId": "6451d6f4-5f82-4659-8564-dc54faf3496a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(67, 67, 68)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_data = np.array(x_data)\n",
        "y_data = np.array(y_data)\n",
        "\n",
        "y_data_onehot = np.array(pd.get_dummies(y_data))"
      ],
      "metadata": {
        "id": "s8nZ_exEjWvh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(x_data[0]), len(y_data_onehot)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cxASmvKNjeAk",
        "outputId": "f661e4c1-b20f-4208-832c-de86ea11a8bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(20, 202)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1.1 train test 분리\n",
        "80:20"
      ],
      "metadata": {
        "id": "_ILOOvUWb3LZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# 분리할 때 20프로, in out nothing 고루 섞이게 stratify 진행\n",
        "x_train, x_test, y_train, y_test = train_test_split(x_data, y_data_onehot, test_size=0.2, shuffle=True, stratify=y_data_onehot, random_state=34)"
      ],
      "metadata": {
        "id": "muweJngWbrpB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train.shape, x_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iI3Ce50GcJ4b",
        "outputId": "2d18cd5e-e0c0-4234-a47b-d050452d34bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((161, 20), (41, 20))"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. 기본 RNN 모델"
      ],
      "metadata": {
        "id": "fDCcMt8He2kZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "acRcZuhxf4Pw"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import SimpleRNN, Dense, LSTM\n",
        "from tensorflow.keras import Sequential\n",
        "\n",
        "from keras.layers import Dropout"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Em98IJ0qf4Py"
      },
      "outputs": [],
      "source": [
        "# 모델 설정\n",
        "model = Sequential()\n",
        "model.add(SimpleRNN(units=256, activation='tanh', input_shape=(20,1)))\n",
        "model.add(Dense(3, activation='softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b3c5615-6558-40d9-b7ea-5b735fbd99bf",
        "id": "IuSYISj5f4Pz"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_78\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " simple_rnn_124 (SimpleRNN)  (None, 256)               66048     \n",
            "                                                                 \n",
            " dense_102 (Dense)           (None, 3)                 771       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 66,819\n",
            "Trainable params: 66,819\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# RNN 레이어 1, FC 레이어 1\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델의 실행 옵션\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "\n",
        "# 모델 저장 조건 설정\n",
        "modelpath = 'RNN_1.hdf5'\n",
        "checkpointer=ModelCheckpoint(filepath=modelpath, monitor='val_loss', verbose=1, save_best_only=True)\n",
        " \n",
        "# 학습 자동 중단 설정\n",
        "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=20)"
      ],
      "metadata": {
        "id": "ZOrKBlqKf4P1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 73% 정확도 (test_accuracy)"
      ],
      "metadata": {
        "id": "auuPSnljjq-G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 실행 (양이 많지 않으므로 배치 크기 1)\n",
        "history = model.fit(x_train, y_train, batch_size=1, epochs=50,\n",
        "                    validation_data = (x_test, y_test), callbacks=[checkpointer, early_stopping_callback])\n",
        "# 결과 출력\n",
        "print(\"\\n Accuracy : %.4f\" %(model.evaluate(x_train,y_train)[1]))"
      ],
      "metadata": {
        "id": "usEU9XRze2sX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "22559c70-ac30-40bf-a75c-5774400ed732"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "157/161 [============================>.] - ETA: 0s - loss: 0.9118 - accuracy: 0.5987\n",
            "Epoch 1: val_loss improved from inf to 0.67795, saving model to RNN_1.hdf5\n",
            "161/161 [==============================] - 2s 9ms/step - loss: 0.9169 - accuracy: 0.5901 - val_loss: 0.6780 - val_accuracy: 0.5366\n",
            "Epoch 2/50\n",
            "155/161 [===========================>..] - ETA: 0s - loss: 0.9162 - accuracy: 0.5484\n",
            "Epoch 2: val_loss improved from 0.67795 to 0.62574, saving model to RNN_1.hdf5\n",
            "161/161 [==============================] - 1s 7ms/step - loss: 0.9072 - accuracy: 0.5466 - val_loss: 0.6257 - val_accuracy: 0.6341\n",
            "Epoch 3/50\n",
            "155/161 [===========================>..] - ETA: 0s - loss: 0.8951 - accuracy: 0.5290\n",
            "Epoch 3: val_loss did not improve from 0.62574\n",
            "161/161 [==============================] - 1s 7ms/step - loss: 0.8889 - accuracy: 0.5342 - val_loss: 0.7082 - val_accuracy: 0.6585\n",
            "Epoch 4/50\n",
            "156/161 [============================>.] - ETA: 0s - loss: 0.7759 - accuracy: 0.6218\n",
            "Epoch 4: val_loss improved from 0.62574 to 0.54794, saving model to RNN_1.hdf5\n",
            "161/161 [==============================] - 1s 8ms/step - loss: 0.7889 - accuracy: 0.6149 - val_loss: 0.5479 - val_accuracy: 0.6585\n",
            "Epoch 5/50\n",
            "161/161 [==============================] - ETA: 0s - loss: 1.0841 - accuracy: 0.4969\n",
            "Epoch 5: val_loss did not improve from 0.54794\n",
            "161/161 [==============================] - 1s 7ms/step - loss: 1.0841 - accuracy: 0.4969 - val_loss: 1.1835 - val_accuracy: 0.3415\n",
            "Epoch 6/50\n",
            "154/161 [===========================>..] - ETA: 0s - loss: 1.1961 - accuracy: 0.3377\n",
            "Epoch 6: val_loss did not improve from 0.54794\n",
            "161/161 [==============================] - 1s 6ms/step - loss: 1.1907 - accuracy: 0.3292 - val_loss: 1.1077 - val_accuracy: 0.3415\n",
            "Epoch 7/50\n",
            "152/161 [===========================>..] - ETA: 0s - loss: 1.1356 - accuracy: 0.3289\n",
            "Epoch 7: val_loss did not improve from 0.54794\n",
            "161/161 [==============================] - 1s 6ms/step - loss: 1.1312 - accuracy: 0.3292 - val_loss: 1.0992 - val_accuracy: 0.3659\n",
            "Epoch 8/50\n",
            "154/161 [===========================>..] - ETA: 0s - loss: 1.1501 - accuracy: 0.3961\n",
            "Epoch 8: val_loss did not improve from 0.54794\n",
            "161/161 [==============================] - 1s 7ms/step - loss: 1.1512 - accuracy: 0.3975 - val_loss: 0.9488 - val_accuracy: 0.7073\n",
            "Epoch 9/50\n",
            "156/161 [============================>.] - ETA: 0s - loss: 0.9713 - accuracy: 0.5192\n",
            "Epoch 9: val_loss did not improve from 0.54794\n",
            "161/161 [==============================] - 1s 8ms/step - loss: 0.9697 - accuracy: 0.5217 - val_loss: 0.8677 - val_accuracy: 0.6341\n",
            "Epoch 10/50\n",
            "160/161 [============================>.] - ETA: 0s - loss: 1.0133 - accuracy: 0.5000\n",
            "Epoch 10: val_loss did not improve from 0.54794\n",
            "161/161 [==============================] - 1s 7ms/step - loss: 1.0174 - accuracy: 0.4969 - val_loss: 1.0181 - val_accuracy: 0.3415\n",
            "Epoch 11/50\n",
            "154/161 [===========================>..] - ETA: 0s - loss: 0.9341 - accuracy: 0.5390\n",
            "Epoch 11: val_loss did not improve from 0.54794\n",
            "161/161 [==============================] - 1s 8ms/step - loss: 0.9627 - accuracy: 0.5217 - val_loss: 1.0752 - val_accuracy: 0.3659\n",
            "Epoch 12/50\n",
            "157/161 [============================>.] - ETA: 0s - loss: 1.0259 - accuracy: 0.4777\n",
            "Epoch 12: val_loss did not improve from 0.54794\n",
            "161/161 [==============================] - 1s 7ms/step - loss: 1.0179 - accuracy: 0.4845 - val_loss: 1.0492 - val_accuracy: 0.3171\n",
            "Epoch 13/50\n",
            "140/161 [=========================>....] - ETA: 0s - loss: 0.9824 - accuracy: 0.4643"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-255-823e4dd12975>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 모델 실행 (양이 많지 않으므로 배치 크기 1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m history = model.fit(x_train, y_train, batch_size=1, epochs=50,\n\u001b[0;32m----> 3\u001b[0;31m                     validation_data = (x_test, y_test), callbacks=[checkpointer, early_stopping_callback])\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;31m# 결과 출력\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n Accuracy : %.4f\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1407\u001b[0m                 _r=1):\n\u001b[1;32m   1408\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1410\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2452\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2453\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2454\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2456\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1859\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1860\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1861\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1862\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1863\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    500\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 502\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    503\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 이런 식으로 학습\n",
        "model.predict(x_train[0].reshape(1,20,1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CHKd9wBtQ1Pc",
        "outputId": "1c415d5e-3b30-4d50-e68b-0d4a66e220bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 133ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.2055003 , 0.5522169 , 0.24228282]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 264
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. 모델 개선"
      ],
      "metadata": {
        "id": "1YdDCDD3e2wA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hTDhaZQhj_AF"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import SimpleRNN, Dense, LSTM\n",
        "from tensorflow.keras import Sequential\n",
        "\n",
        "from keras.layers import Dropout"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 변경 기록\n",
        "1. unit 수 감소 (256에서 128로) 63% ->256이 최적\n",
        "2. optimizer 비교 했을 때 sgd 보다는 adam 이 준수함\n",
        "3. fc 레이어 층 하나 추가 (레이어 100, ReLU) ->33%\n",
        "4. fc 레이어 층 하나 추가 (레이어 100, tanh) ->63%   // 그나마 tanh\n",
        "5. fc 레이어 층 하나 추가 (레이어 50, tanh) ->33% // 그나마 레이어 100개\n",
        "6. fc 레이어 3개 추가 해보고 드랍아웃 추가? -> 레이어 추가 도움 안 됨\n",
        "\n",
        "\n",
        "---\n",
        "#### 지금까지를 봤을 때 simple rnn + output layer과 준수한 성적\n",
        "\n",
        "\n",
        "---\n",
        "#### 그럼 RNN 두개?\n",
        "\n",
        "\n",
        "1. RNN 256(tanh) -> RNN 128(relu) 낫배드\n",
        "2. RNN 256(relu) -> RNN 128(relu) -> 처음 활성화는 무조건 tanh\n",
        "3. rnn 256(tanh) -> rnn 100(relu) -> rnn 50(relu) // 3개는 too much\n",
        "4. 2번으로 돌아가서 dropout만 추가 // dropout 도움 안 됨\n",
        "5. 2번으로 돌아가서 fc layer 하나 추가\n",
        "\n",
        "### 레이어 늘리는 건 도움이 안 됨\n",
        "차라리 optimizer를 여러번 바꿔보자\n",
        "1. sgd 0.3\n",
        "2. adam 0.7\n",
        "3. RMSprop 0.65\n",
        "4. Adadelta 0.7 지속적으로 증가 발생\n",
        "5. Adagrad 0.7\n",
        "6. Nadam 0.6\n",
        "## optimizer는 adam adagrad adadelta 가 괜찮음\n",
        "\n",
        "## 먼저 adadelta로 층 늘려보자\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "efsNGFO3kqNa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 참고로 모델에 들어가는 크기\n",
        "x_train[0].shape"
      ],
      "metadata": {
        "id": "v0BFO-BDoVNW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0187b73b-3e38-4722-9da6-9ace4b50b060"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(20,)"
            ]
          },
          "metadata": {},
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oCpit8xEj_AF"
      },
      "outputs": [],
      "source": [
        "# 모델 설정\n",
        "model = Sequential()\n",
        "# many to many 문제를 풀거나 레이어를 여러개로 쌓아올릴 때는 return_sequence=True 를 사용\n",
        "model.add(SimpleRNN(units=256, activation='tanh', input_shape=(20,1))) #, return_sequences=True))\n",
        "model.add(Dense(20, activation='ReLU'))\n",
        "model.add(Dense(20, activation='ReLU'))\n",
        "model.add(Dense(3, activation='softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "24bb88ba-dab7-47b5-99f2-f8855aefc257",
        "id": "xzu9s1XRj_AG"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_52\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " simple_rnn_75 (SimpleRNN)   (None, 256)               66048     \n",
            "                                                                 \n",
            " dense_57 (Dense)            (None, 20)                5140      \n",
            "                                                                 \n",
            " dense_58 (Dense)            (None, 20)                420       \n",
            "                                                                 \n",
            " dense_59 (Dense)            (None, 3)                 63        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 71,671\n",
            "Trainable params: 71,671\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# RNN 레이어 1, FC 레이어 1\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델의 실행 옵션\n",
        "# optimizer\n",
        "# adam, sgd,\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adagrad', metrics=['accuracy'])\n",
        "\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "\n",
        "# 모델 저장 조건 설정\n",
        "modelpath = 'RNN_3.hdf5'\n",
        "checkpointer=ModelCheckpoint(filepath=modelpath, monitor='val_loss', verbose=1, save_best_only=True)\n",
        " \n",
        "# 학습 자동 중단 설정\n",
        "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=20)"
      ],
      "metadata": {
        "id": "QxFFiNi7j_AG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 실행 (양이 많지 않으므로 배치 크기 1)\n",
        "history = model.fit(x_train, y_train, batch_size=1, epochs=80,\n",
        "                    validation_data = (x_test, y_test), callbacks=[checkpointer, early_stopping_callback])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6h3Dhl67ksw3",
        "outputId": "fe9831d8-5bcb-4a67-cb52-db44158ef04a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/80\n",
            "159/161 [============================>.] - ETA: 0s - loss: 1.1056 - accuracy: 0.3396\n",
            "Epoch 1: val_loss improved from inf to 1.06534, saving model to RNN_2.hdf5\n",
            "161/161 [==============================] - 2s 9ms/step - loss: 1.1056 - accuracy: 0.3416 - val_loss: 1.0653 - val_accuracy: 0.3171\n",
            "Epoch 2/80\n",
            "160/161 [============================>.] - ETA: 0s - loss: 1.0532 - accuracy: 0.4313\n",
            "Epoch 2: val_loss improved from 1.06534 to 1.02685, saving model to RNN_2.hdf5\n",
            "161/161 [==============================] - 1s 8ms/step - loss: 1.0521 - accuracy: 0.4348 - val_loss: 1.0268 - val_accuracy: 0.5610\n",
            "Epoch 3/80\n",
            "155/161 [===========================>..] - ETA: 0s - loss: 1.0234 - accuracy: 0.5419\n",
            "Epoch 3: val_loss improved from 1.02685 to 0.99289, saving model to RNN_2.hdf5\n",
            "161/161 [==============================] - 1s 8ms/step - loss: 1.0219 - accuracy: 0.5404 - val_loss: 0.9929 - val_accuracy: 0.6341\n",
            "Epoch 4/80\n",
            "157/161 [============================>.] - ETA: 0s - loss: 0.9951 - accuracy: 0.5987\n",
            "Epoch 4: val_loss improved from 0.99289 to 0.95831, saving model to RNN_2.hdf5\n",
            "161/161 [==============================] - 1s 8ms/step - loss: 0.9948 - accuracy: 0.5963 - val_loss: 0.9583 - val_accuracy: 0.6585\n",
            "Epoch 5/80\n",
            "155/161 [===========================>..] - ETA: 0s - loss: 0.9665 - accuracy: 0.5871\n",
            "Epoch 5: val_loss improved from 0.95831 to 0.93575, saving model to RNN_2.hdf5\n",
            "161/161 [==============================] - 1s 7ms/step - loss: 0.9632 - accuracy: 0.5901 - val_loss: 0.9357 - val_accuracy: 0.6341\n",
            "Epoch 6/80\n",
            "160/161 [============================>.] - ETA: 0s - loss: 0.9265 - accuracy: 0.5813\n",
            "Epoch 6: val_loss did not improve from 0.93575\n",
            "161/161 [==============================] - 1s 7ms/step - loss: 0.9279 - accuracy: 0.5776 - val_loss: 0.9433 - val_accuracy: 0.6341\n",
            "Epoch 7/80\n",
            "159/161 [============================>.] - ETA: 0s - loss: 0.9089 - accuracy: 0.6289\n",
            "Epoch 7: val_loss improved from 0.93575 to 0.85993, saving model to RNN_2.hdf5\n",
            "161/161 [==============================] - 1s 9ms/step - loss: 0.9093 - accuracy: 0.6273 - val_loss: 0.8599 - val_accuracy: 0.6585\n",
            "Epoch 8/80\n",
            "152/161 [===========================>..] - ETA: 0s - loss: 0.8699 - accuracy: 0.6316\n",
            "Epoch 8: val_loss improved from 0.85993 to 0.83030, saving model to RNN_2.hdf5\n",
            "161/161 [==============================] - 1s 7ms/step - loss: 0.8763 - accuracy: 0.6273 - val_loss: 0.8303 - val_accuracy: 0.6341\n",
            "Epoch 9/80\n",
            "160/161 [============================>.] - ETA: 0s - loss: 0.8468 - accuracy: 0.6313\n",
            "Epoch 9: val_loss improved from 0.83030 to 0.78656, saving model to RNN_2.hdf5\n",
            "161/161 [==============================] - 1s 7ms/step - loss: 0.8482 - accuracy: 0.6273 - val_loss: 0.7866 - val_accuracy: 0.6585\n",
            "Epoch 10/80\n",
            "158/161 [============================>.] - ETA: 0s - loss: 0.8177 - accuracy: 0.6456\n",
            "Epoch 10: val_loss improved from 0.78656 to 0.74947, saving model to RNN_2.hdf5\n",
            "161/161 [==============================] - 1s 8ms/step - loss: 0.8179 - accuracy: 0.6460 - val_loss: 0.7495 - val_accuracy: 0.7073\n",
            "Epoch 11/80\n",
            "161/161 [==============================] - ETA: 0s - loss: 0.7886 - accuracy: 0.6398\n",
            "Epoch 11: val_loss improved from 0.74947 to 0.74882, saving model to RNN_2.hdf5\n",
            "161/161 [==============================] - 1s 7ms/step - loss: 0.7886 - accuracy: 0.6398 - val_loss: 0.7488 - val_accuracy: 0.6341\n",
            "Epoch 12/80\n",
            "160/161 [============================>.] - ETA: 0s - loss: 0.7624 - accuracy: 0.6562\n",
            "Epoch 12: val_loss improved from 0.74882 to 0.69269, saving model to RNN_2.hdf5\n",
            "161/161 [==============================] - 2s 10ms/step - loss: 0.7636 - accuracy: 0.6522 - val_loss: 0.6927 - val_accuracy: 0.6585\n",
            "Epoch 13/80\n",
            "157/161 [============================>.] - ETA: 0s - loss: 0.7353 - accuracy: 0.6752\n",
            "Epoch 13: val_loss improved from 0.69269 to 0.66833, saving model to RNN_2.hdf5\n",
            "161/161 [==============================] - 2s 11ms/step - loss: 0.7498 - accuracy: 0.6646 - val_loss: 0.6683 - val_accuracy: 0.6585\n",
            "Epoch 14/80\n",
            "161/161 [==============================] - ETA: 0s - loss: 0.7313 - accuracy: 0.6398\n",
            "Epoch 14: val_loss improved from 0.66833 to 0.65010, saving model to RNN_2.hdf5\n",
            "161/161 [==============================] - 1s 8ms/step - loss: 0.7313 - accuracy: 0.6398 - val_loss: 0.6501 - val_accuracy: 0.6585\n",
            "Epoch 15/80\n",
            "159/161 [============================>.] - ETA: 0s - loss: 0.7258 - accuracy: 0.6541\n",
            "Epoch 15: val_loss improved from 0.65010 to 0.64062, saving model to RNN_2.hdf5\n",
            "161/161 [==============================] - 1s 6ms/step - loss: 0.7238 - accuracy: 0.6522 - val_loss: 0.6406 - val_accuracy: 0.7317\n",
            "Epoch 16/80\n",
            "155/161 [===========================>..] - ETA: 0s - loss: 0.7225 - accuracy: 0.6581\n",
            "Epoch 16: val_loss improved from 0.64062 to 0.62044, saving model to RNN_2.hdf5\n",
            "161/161 [==============================] - 1s 6ms/step - loss: 0.7166 - accuracy: 0.6646 - val_loss: 0.6204 - val_accuracy: 0.6829\n",
            "Epoch 17/80\n",
            "158/161 [============================>.] - ETA: 0s - loss: 0.7124 - accuracy: 0.6519\n",
            "Epoch 17: val_loss improved from 0.62044 to 0.61226, saving model to RNN_2.hdf5\n",
            "161/161 [==============================] - 1s 7ms/step - loss: 0.7100 - accuracy: 0.6522 - val_loss: 0.6123 - val_accuracy: 0.6829\n",
            "Epoch 18/80\n",
            "161/161 [==============================] - ETA: 0s - loss: 0.6992 - accuracy: 0.6584\n",
            "Epoch 18: val_loss improved from 0.61226 to 0.60305, saving model to RNN_2.hdf5\n",
            "161/161 [==============================] - 1s 7ms/step - loss: 0.6992 - accuracy: 0.6584 - val_loss: 0.6031 - val_accuracy: 0.6829\n",
            "Epoch 19/80\n",
            "159/161 [============================>.] - ETA: 0s - loss: 0.6964 - accuracy: 0.6541\n",
            "Epoch 19: val_loss improved from 0.60305 to 0.60230, saving model to RNN_2.hdf5\n",
            "161/161 [==============================] - 1s 8ms/step - loss: 0.6992 - accuracy: 0.6584 - val_loss: 0.6023 - val_accuracy: 0.7073\n",
            "Epoch 20/80\n",
            "156/161 [============================>.] - ETA: 0s - loss: 0.6978 - accuracy: 0.6859\n",
            "Epoch 20: val_loss improved from 0.60230 to 0.58888, saving model to RNN_2.hdf5\n",
            "161/161 [==============================] - 1s 7ms/step - loss: 0.6893 - accuracy: 0.6894 - val_loss: 0.5889 - val_accuracy: 0.7317\n",
            "Epoch 21/80\n",
            "154/161 [===========================>..] - ETA: 0s - loss: 0.6863 - accuracy: 0.6753\n",
            "Epoch 21: val_loss improved from 0.58888 to 0.58823, saving model to RNN_2.hdf5\n",
            "161/161 [==============================] - 1s 6ms/step - loss: 0.6922 - accuracy: 0.6646 - val_loss: 0.5882 - val_accuracy: 0.6829\n",
            "Epoch 22/80\n",
            "159/161 [============================>.] - ETA: 0s - loss: 0.6912 - accuracy: 0.6478\n",
            "Epoch 22: val_loss improved from 0.58823 to 0.58243, saving model to RNN_2.hdf5\n",
            "161/161 [==============================] - 1s 7ms/step - loss: 0.6879 - accuracy: 0.6522 - val_loss: 0.5824 - val_accuracy: 0.7317\n",
            "Epoch 23/80\n",
            "156/161 [============================>.] - ETA: 0s - loss: 0.6804 - accuracy: 0.6603\n",
            "Epoch 23: val_loss improved from 0.58243 to 0.57962, saving model to RNN_2.hdf5\n",
            "161/161 [==============================] - 1s 6ms/step - loss: 0.6784 - accuracy: 0.6646 - val_loss: 0.5796 - val_accuracy: 0.7317\n",
            "Epoch 24/80\n",
            "155/161 [===========================>..] - ETA: 0s - loss: 0.6748 - accuracy: 0.6839\n",
            "Epoch 24: val_loss improved from 0.57962 to 0.57429, saving model to RNN_2.hdf5\n",
            "161/161 [==============================] - 1s 8ms/step - loss: 0.6764 - accuracy: 0.6832 - val_loss: 0.5743 - val_accuracy: 0.7073\n",
            "Epoch 25/80\n",
            "157/161 [============================>.] - ETA: 0s - loss: 0.6761 - accuracy: 0.6943\n",
            "Epoch 25: val_loss did not improve from 0.57429\n",
            "161/161 [==============================] - 1s 7ms/step - loss: 0.6724 - accuracy: 0.6894 - val_loss: 0.5780 - val_accuracy: 0.6585\n",
            "Epoch 26/80\n",
            "161/161 [==============================] - ETA: 0s - loss: 0.6749 - accuracy: 0.6646\n",
            "Epoch 26: val_loss improved from 0.57429 to 0.56823, saving model to RNN_2.hdf5\n",
            "161/161 [==============================] - 1s 6ms/step - loss: 0.6749 - accuracy: 0.6646 - val_loss: 0.5682 - val_accuracy: 0.7317\n",
            "Epoch 27/80\n",
            "157/161 [============================>.] - ETA: 0s - loss: 0.6716 - accuracy: 0.6752\n",
            "Epoch 27: val_loss improved from 0.56823 to 0.56316, saving model to RNN_2.hdf5\n",
            "161/161 [==============================] - 1s 8ms/step - loss: 0.6714 - accuracy: 0.6708 - val_loss: 0.5632 - val_accuracy: 0.7317\n",
            "Epoch 28/80\n",
            "158/161 [============================>.] - ETA: 0s - loss: 0.6671 - accuracy: 0.6646\n",
            "Epoch 28: val_loss improved from 0.56316 to 0.55977, saving model to RNN_2.hdf5\n",
            "161/161 [==============================] - 2s 10ms/step - loss: 0.6683 - accuracy: 0.6646 - val_loss: 0.5598 - val_accuracy: 0.7317\n",
            "Epoch 29/80\n",
            "158/161 [============================>.] - ETA: 0s - loss: 0.6688 - accuracy: 0.6835\n",
            "Epoch 29: val_loss improved from 0.55977 to 0.55817, saving model to RNN_2.hdf5\n",
            "161/161 [==============================] - 1s 8ms/step - loss: 0.6650 - accuracy: 0.6894 - val_loss: 0.5582 - val_accuracy: 0.7073\n",
            "Epoch 30/80\n",
            "157/161 [============================>.] - ETA: 0s - loss: 0.6650 - accuracy: 0.6561\n",
            "Epoch 30: val_loss improved from 0.55817 to 0.55738, saving model to RNN_2.hdf5\n",
            "161/161 [==============================] - 1s 8ms/step - loss: 0.6634 - accuracy: 0.6584 - val_loss: 0.5574 - val_accuracy: 0.7317\n",
            "Epoch 31/80\n",
            "161/161 [==============================] - ETA: 0s - loss: 0.6630 - accuracy: 0.6770\n",
            "Epoch 31: val_loss did not improve from 0.55738\n",
            "161/161 [==============================] - 1s 7ms/step - loss: 0.6630 - accuracy: 0.6770 - val_loss: 0.5612 - val_accuracy: 0.6829\n",
            "Epoch 32/80\n",
            "154/161 [===========================>..] - ETA: 0s - loss: 0.6490 - accuracy: 0.6883\n",
            "Epoch 32: val_loss improved from 0.55738 to 0.55134, saving model to RNN_2.hdf5\n",
            "161/161 [==============================] - 1s 8ms/step - loss: 0.6580 - accuracy: 0.6770 - val_loss: 0.5513 - val_accuracy: 0.7317\n",
            "Epoch 33/80\n",
            "153/161 [===========================>..] - ETA: 0s - loss: 0.6457 - accuracy: 0.6797\n",
            "Epoch 33: val_loss did not improve from 0.55134\n",
            "161/161 [==============================] - 1s 7ms/step - loss: 0.6604 - accuracy: 0.6708 - val_loss: 0.5531 - val_accuracy: 0.7317\n",
            "Epoch 34/80\n",
            "156/161 [============================>.] - ETA: 0s - loss: 0.6566 - accuracy: 0.6859\n",
            "Epoch 34: val_loss did not improve from 0.55134\n",
            "161/161 [==============================] - 1s 7ms/step - loss: 0.6539 - accuracy: 0.6894 - val_loss: 0.5791 - val_accuracy: 0.6585\n",
            "Epoch 35/80\n",
            "159/161 [============================>.] - ETA: 0s - loss: 0.6515 - accuracy: 0.6792\n",
            "Epoch 35: val_loss improved from 0.55134 to 0.54915, saving model to RNN_2.hdf5\n",
            "161/161 [==============================] - 1s 7ms/step - loss: 0.6593 - accuracy: 0.6770 - val_loss: 0.5491 - val_accuracy: 0.7317\n",
            "Epoch 36/80\n",
            "153/161 [===========================>..] - ETA: 0s - loss: 0.6354 - accuracy: 0.6863\n",
            "Epoch 36: val_loss did not improve from 0.54915\n",
            "161/161 [==============================] - 1s 7ms/step - loss: 0.6526 - accuracy: 0.6770 - val_loss: 0.5711 - val_accuracy: 0.6829\n",
            "Epoch 37/80\n",
            "161/161 [==============================] - ETA: 0s - loss: 0.6558 - accuracy: 0.6832\n",
            "Epoch 37: val_loss did not improve from 0.54915\n",
            "161/161 [==============================] - 1s 7ms/step - loss: 0.6558 - accuracy: 0.6832 - val_loss: 0.5516 - val_accuracy: 0.7073\n",
            "Epoch 38/80\n",
            "158/161 [============================>.] - ETA: 0s - loss: 0.6517 - accuracy: 0.6835\n",
            "Epoch 38: val_loss improved from 0.54915 to 0.54536, saving model to RNN_2.hdf5\n",
            "161/161 [==============================] - 1s 7ms/step - loss: 0.6519 - accuracy: 0.6770 - val_loss: 0.5454 - val_accuracy: 0.7317\n",
            "Epoch 39/80\n",
            "161/161 [==============================] - ETA: 0s - loss: 0.6508 - accuracy: 0.6770\n",
            "Epoch 39: val_loss improved from 0.54536 to 0.54287, saving model to RNN_2.hdf5\n",
            "161/161 [==============================] - 1s 7ms/step - loss: 0.6508 - accuracy: 0.6770 - val_loss: 0.5429 - val_accuracy: 0.7317\n",
            "Epoch 40/80\n",
            "154/161 [===========================>..] - ETA: 0s - loss: 0.6487 - accuracy: 0.6818\n",
            "Epoch 40: val_loss did not improve from 0.54287\n",
            "161/161 [==============================] - 1s 8ms/step - loss: 0.6481 - accuracy: 0.6832 - val_loss: 0.5569 - val_accuracy: 0.6585\n",
            "Epoch 41/80\n",
            "154/161 [===========================>..] - ETA: 0s - loss: 0.6485 - accuracy: 0.6948\n",
            "Epoch 41: val_loss did not improve from 0.54287\n",
            "161/161 [==============================] - 1s 7ms/step - loss: 0.6456 - accuracy: 0.6957 - val_loss: 0.5661 - val_accuracy: 0.6829\n",
            "Epoch 42/80\n",
            "160/161 [============================>.] - ETA: 0s - loss: 0.6572 - accuracy: 0.6687\n",
            "Epoch 42: val_loss improved from 0.54287 to 0.53979, saving model to RNN_2.hdf5\n",
            "161/161 [==============================] - 1s 7ms/step - loss: 0.6587 - accuracy: 0.6646 - val_loss: 0.5398 - val_accuracy: 0.7317\n",
            "Epoch 43/80\n",
            "158/161 [============================>.] - ETA: 0s - loss: 0.6468 - accuracy: 0.6772\n",
            "Epoch 43: val_loss improved from 0.53979 to 0.53865, saving model to RNN_2.hdf5\n",
            "161/161 [==============================] - 1s 7ms/step - loss: 0.6468 - accuracy: 0.6708 - val_loss: 0.5387 - val_accuracy: 0.7317\n",
            "Epoch 44/80\n",
            "157/161 [============================>.] - ETA: 0s - loss: 0.6458 - accuracy: 0.6752\n",
            "Epoch 44: val_loss did not improve from 0.53865\n",
            "161/161 [==============================] - 1s 8ms/step - loss: 0.6395 - accuracy: 0.6832 - val_loss: 0.5747 - val_accuracy: 0.6829\n",
            "Epoch 45/80\n",
            "159/161 [============================>.] - ETA: 0s - loss: 0.6495 - accuracy: 0.6730\n",
            "Epoch 45: val_loss did not improve from 0.53865\n",
            "161/161 [==============================] - 1s 8ms/step - loss: 0.6488 - accuracy: 0.6770 - val_loss: 0.5465 - val_accuracy: 0.6829\n",
            "Epoch 46/80\n",
            "158/161 [============================>.] - ETA: 0s - loss: 0.6364 - accuracy: 0.6899\n",
            "Epoch 46: val_loss did not improve from 0.53865\n",
            "161/161 [==============================] - 2s 10ms/step - loss: 0.6422 - accuracy: 0.6894 - val_loss: 0.5732 - val_accuracy: 0.6829\n",
            "Epoch 47/80\n",
            "158/161 [============================>.] - ETA: 0s - loss: 0.6441 - accuracy: 0.6835\n",
            "Epoch 47: val_loss improved from 0.53865 to 0.53695, saving model to RNN_2.hdf5\n",
            "161/161 [==============================] - 2s 13ms/step - loss: 0.6511 - accuracy: 0.6770 - val_loss: 0.5370 - val_accuracy: 0.7317\n",
            "Epoch 48/80\n",
            "161/161 [==============================] - ETA: 0s - loss: 0.6436 - accuracy: 0.6770\n",
            "Epoch 48: val_loss did not improve from 0.53695\n",
            "161/161 [==============================] - 1s 8ms/step - loss: 0.6436 - accuracy: 0.6770 - val_loss: 0.5386 - val_accuracy: 0.7317\n",
            "Epoch 49/80\n",
            "156/161 [============================>.] - ETA: 0s - loss: 0.6505 - accuracy: 0.6731\n",
            "Epoch 49: val_loss improved from 0.53695 to 0.53577, saving model to RNN_2.hdf5\n",
            "161/161 [==============================] - 1s 7ms/step - loss: 0.6435 - accuracy: 0.6770 - val_loss: 0.5358 - val_accuracy: 0.7317\n",
            "Epoch 50/80\n",
            "157/161 [============================>.] - ETA: 0s - loss: 0.6464 - accuracy: 0.6688\n",
            "Epoch 50: val_loss improved from 0.53577 to 0.53507, saving model to RNN_2.hdf5\n",
            "161/161 [==============================] - 1s 8ms/step - loss: 0.6454 - accuracy: 0.6646 - val_loss: 0.5351 - val_accuracy: 0.7317\n",
            "Epoch 51/80\n",
            "158/161 [============================>.] - ETA: 0s - loss: 0.6431 - accuracy: 0.7025\n",
            "Epoch 51: val_loss did not improve from 0.53507\n",
            "161/161 [==============================] - 1s 8ms/step - loss: 0.6385 - accuracy: 0.7019 - val_loss: 0.5524 - val_accuracy: 0.6585\n",
            "Epoch 52/80\n",
            "154/161 [===========================>..] - ETA: 0s - loss: 0.6483 - accuracy: 0.6623\n",
            "Epoch 52: val_loss did not improve from 0.53507\n",
            "161/161 [==============================] - 1s 7ms/step - loss: 0.6371 - accuracy: 0.6770 - val_loss: 0.5528 - val_accuracy: 0.6829\n",
            "Epoch 53/80\n",
            "155/161 [===========================>..] - ETA: 0s - loss: 0.6526 - accuracy: 0.6839\n",
            "Epoch 53: val_loss did not improve from 0.53507\n",
            "161/161 [==============================] - 1s 7ms/step - loss: 0.6433 - accuracy: 0.6894 - val_loss: 0.5455 - val_accuracy: 0.6829\n",
            "Epoch 54/80\n",
            "155/161 [===========================>..] - ETA: 0s - loss: 0.6488 - accuracy: 0.6968\n",
            "Epoch 54: val_loss improved from 0.53507 to 0.53304, saving model to RNN_2.hdf5\n",
            "161/161 [==============================] - 1s 8ms/step - loss: 0.6408 - accuracy: 0.6957 - val_loss: 0.5330 - val_accuracy: 0.7317\n",
            "Epoch 55/80\n",
            "160/161 [============================>.] - ETA: 0s - loss: 0.6375 - accuracy: 0.6875\n",
            "Epoch 55: val_loss did not improve from 0.53304\n",
            "161/161 [==============================] - 1s 7ms/step - loss: 0.6373 - accuracy: 0.6894 - val_loss: 0.5400 - val_accuracy: 0.6829\n",
            "Epoch 56/80\n",
            "161/161 [==============================] - ETA: 0s - loss: 0.6411 - accuracy: 0.6708\n",
            "Epoch 56: val_loss improved from 0.53304 to 0.53044, saving model to RNN_2.hdf5\n",
            "161/161 [==============================] - 1s 8ms/step - loss: 0.6411 - accuracy: 0.6708 - val_loss: 0.5304 - val_accuracy: 0.7317\n",
            "Epoch 57/80\n",
            "154/161 [===========================>..] - ETA: 0s - loss: 0.6413 - accuracy: 0.6753\n",
            "Epoch 57: val_loss improved from 0.53044 to 0.52973, saving model to RNN_2.hdf5\n",
            "161/161 [==============================] - 1s 7ms/step - loss: 0.6394 - accuracy: 0.6770 - val_loss: 0.5297 - val_accuracy: 0.7073\n",
            "Epoch 58/80\n",
            "156/161 [============================>.] - ETA: 0s - loss: 0.6429 - accuracy: 0.6731\n",
            "Epoch 58: val_loss did not improve from 0.52973\n",
            "161/161 [==============================] - 1s 8ms/step - loss: 0.6385 - accuracy: 0.6770 - val_loss: 0.5306 - val_accuracy: 0.7317\n",
            "Epoch 59/80\n",
            "156/161 [============================>.] - ETA: 0s - loss: 0.6357 - accuracy: 0.6923\n",
            "Epoch 59: val_loss did not improve from 0.52973\n",
            "161/161 [==============================] - 1s 9ms/step - loss: 0.6376 - accuracy: 0.6894 - val_loss: 0.5397 - val_accuracy: 0.6829\n",
            "Epoch 60/80\n",
            "156/161 [============================>.] - ETA: 0s - loss: 0.6405 - accuracy: 0.6603\n",
            "Epoch 60: val_loss did not improve from 0.52973\n",
            "161/161 [==============================] - 1s 8ms/step - loss: 0.6355 - accuracy: 0.6708 - val_loss: 0.5444 - val_accuracy: 0.6585\n",
            "Epoch 61/80\n",
            "153/161 [===========================>..] - ETA: 0s - loss: 0.6162 - accuracy: 0.7059\n",
            "Epoch 61: val_loss improved from 0.52973 to 0.52938, saving model to RNN_2.hdf5\n",
            "161/161 [==============================] - 1s 8ms/step - loss: 0.6409 - accuracy: 0.6894 - val_loss: 0.5294 - val_accuracy: 0.7317\n",
            "Epoch 62/80\n",
            "155/161 [===========================>..] - ETA: 0s - loss: 0.6266 - accuracy: 0.6903\n",
            "Epoch 62: val_loss did not improve from 0.52938\n",
            "161/161 [==============================] - 1s 7ms/step - loss: 0.6368 - accuracy: 0.6894 - val_loss: 0.5333 - val_accuracy: 0.7317\n",
            "Epoch 63/80\n",
            "158/161 [============================>.] - ETA: 0s - loss: 0.6422 - accuracy: 0.6835\n",
            "Epoch 63: val_loss did not improve from 0.52938\n",
            "161/161 [==============================] - 1s 6ms/step - loss: 0.6355 - accuracy: 0.6894 - val_loss: 0.5297 - val_accuracy: 0.7317\n",
            "Epoch 64/80\n",
            "154/161 [===========================>..] - ETA: 0s - loss: 0.6324 - accuracy: 0.6948\n",
            "Epoch 64: val_loss did not improve from 0.52938\n",
            "161/161 [==============================] - 1s 7ms/step - loss: 0.6321 - accuracy: 0.6957 - val_loss: 0.5386 - val_accuracy: 0.6829\n",
            "Epoch 65/80\n",
            "159/161 [============================>.] - ETA: 0s - loss: 0.6399 - accuracy: 0.6918\n",
            "Epoch 65: val_loss did not improve from 0.52938\n",
            "161/161 [==============================] - 1s 6ms/step - loss: 0.6359 - accuracy: 0.6957 - val_loss: 0.5310 - val_accuracy: 0.7317\n",
            "Epoch 66/80\n",
            "155/161 [===========================>..] - ETA: 0s - loss: 0.6394 - accuracy: 0.6774\n",
            "Epoch 66: val_loss did not improve from 0.52938\n",
            "161/161 [==============================] - 1s 7ms/step - loss: 0.6344 - accuracy: 0.6832 - val_loss: 0.5322 - val_accuracy: 0.7317\n",
            "Epoch 67/80\n",
            "160/161 [============================>.] - ETA: 0s - loss: 0.6354 - accuracy: 0.6938\n",
            "Epoch 67: val_loss improved from 0.52938 to 0.52829, saving model to RNN_2.hdf5\n",
            "161/161 [==============================] - 1s 7ms/step - loss: 0.6352 - accuracy: 0.6957 - val_loss: 0.5283 - val_accuracy: 0.7317\n",
            "Epoch 68/80\n",
            "161/161 [==============================] - ETA: 0s - loss: 0.6345 - accuracy: 0.6832\n",
            "Epoch 68: val_loss improved from 0.52829 to 0.52677, saving model to RNN_2.hdf5\n",
            "161/161 [==============================] - 1s 8ms/step - loss: 0.6345 - accuracy: 0.6832 - val_loss: 0.5268 - val_accuracy: 0.7317\n",
            "Epoch 69/80\n",
            "161/161 [==============================] - ETA: 0s - loss: 0.6359 - accuracy: 0.6832\n",
            "Epoch 69: val_loss did not improve from 0.52677\n",
            "161/161 [==============================] - 1s 8ms/step - loss: 0.6359 - accuracy: 0.6832 - val_loss: 0.5297 - val_accuracy: 0.7317\n",
            "Epoch 70/80\n",
            "155/161 [===========================>..] - ETA: 0s - loss: 0.6381 - accuracy: 0.6710\n",
            "Epoch 70: val_loss did not improve from 0.52677\n",
            "161/161 [==============================] - 1s 8ms/step - loss: 0.6319 - accuracy: 0.6770 - val_loss: 0.5406 - val_accuracy: 0.6585\n",
            "Epoch 71/80\n",
            "156/161 [============================>.] - ETA: 0s - loss: 0.6320 - accuracy: 0.6987\n",
            "Epoch 71: val_loss did not improve from 0.52677\n",
            "161/161 [==============================] - 1s 7ms/step - loss: 0.6318 - accuracy: 0.6957 - val_loss: 0.5358 - val_accuracy: 0.6829\n",
            "Epoch 72/80\n",
            "158/161 [============================>.] - ETA: 0s - loss: 0.6197 - accuracy: 0.6899\n",
            "Epoch 72: val_loss did not improve from 0.52677\n",
            "161/161 [==============================] - 1s 8ms/step - loss: 0.6341 - accuracy: 0.6894 - val_loss: 0.5276 - val_accuracy: 0.7317\n",
            "Epoch 73/80\n",
            "158/161 [============================>.] - ETA: 0s - loss: 0.6281 - accuracy: 0.7089\n",
            "Epoch 73: val_loss did not improve from 0.52677\n",
            "161/161 [==============================] - 1s 8ms/step - loss: 0.6328 - accuracy: 0.6957 - val_loss: 0.5269 - val_accuracy: 0.7317\n",
            "Epoch 74/80\n",
            "159/161 [============================>.] - ETA: 0s - loss: 0.6276 - accuracy: 0.6918\n",
            "Epoch 74: val_loss did not improve from 0.52677\n",
            "161/161 [==============================] - 1s 7ms/step - loss: 0.6316 - accuracy: 0.6894 - val_loss: 0.5351 - val_accuracy: 0.6829\n",
            "Epoch 75/80\n",
            "158/161 [============================>.] - ETA: 0s - loss: 0.6314 - accuracy: 0.6962\n",
            "Epoch 75: val_loss did not improve from 0.52677\n",
            "161/161 [==============================] - 1s 7ms/step - loss: 0.6330 - accuracy: 0.6957 - val_loss: 0.5292 - val_accuracy: 0.7317\n",
            "Epoch 76/80\n",
            "158/161 [============================>.] - ETA: 0s - loss: 0.6389 - accuracy: 0.6962\n",
            "Epoch 76: val_loss improved from 0.52677 to 0.52642, saving model to RNN_2.hdf5\n",
            "161/161 [==============================] - 1s 8ms/step - loss: 0.6332 - accuracy: 0.6957 - val_loss: 0.5264 - val_accuracy: 0.7317\n",
            "Epoch 77/80\n",
            "161/161 [==============================] - ETA: 0s - loss: 0.6267 - accuracy: 0.7019\n",
            "Epoch 77: val_loss did not improve from 0.52642\n",
            "161/161 [==============================] - 1s 7ms/step - loss: 0.6267 - accuracy: 0.7019 - val_loss: 0.5472 - val_accuracy: 0.6829\n",
            "Epoch 78/80\n",
            "160/161 [============================>.] - ETA: 0s - loss: 0.6343 - accuracy: 0.6687\n",
            "Epoch 78: val_loss improved from 0.52642 to 0.52542, saving model to RNN_2.hdf5\n",
            "161/161 [==============================] - 1s 7ms/step - loss: 0.6340 - accuracy: 0.6708 - val_loss: 0.5254 - val_accuracy: 0.7317\n",
            "Epoch 79/80\n",
            "156/161 [============================>.] - ETA: 0s - loss: 0.6326 - accuracy: 0.6859\n",
            "Epoch 79: val_loss did not improve from 0.52542\n",
            "161/161 [==============================] - 1s 7ms/step - loss: 0.6302 - accuracy: 0.6894 - val_loss: 0.5280 - val_accuracy: 0.7317\n",
            "Epoch 80/80\n",
            "157/161 [============================>.] - ETA: 0s - loss: 0.6106 - accuracy: 0.7070\n",
            "Epoch 80: val_loss improved from 0.52542 to 0.52378, saving model to RNN_2.hdf5\n",
            "161/161 [==============================] - 1s 7ms/step - loss: 0.6294 - accuracy: 0.6957 - val_loss: 0.5238 - val_accuracy: 0.7317\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# adadelta로 73프로까지 끌어올림\n",
        "층 추가 + dropout 추가해서 진행\n",
        "* 73% ~ 75% 사이"
      ],
      "metadata": {
        "id": "qR_wawfMmsx3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 층 더 추가하기 - 최종 82.9% 정확도"
      ],
      "metadata": {
        "id": "yrwGXQ409qMA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "raZ0QlV51wTB"
      },
      "outputs": [],
      "source": [
        "# 모델 설정\n",
        "model = Sequential()\n",
        "# many to many 문제를 풀거나 레이어를 여러개로 쌓아올릴 때는 return_sequence=True 를 쌓는 앞 레이어에 쌓음\n",
        "model.add(SimpleRNN(units=256, activation='tanh', input_shape=(20,1), return_sequences=True))\n",
        "model.add(SimpleRNN(units=128, activation='ReLU', input_shape=(20,1)))\n",
        "model.add(Dense(64, activation='ReLU'))\n",
        "model.add(Dropout(0.1))\n",
        "model.add(Dense(32, activation='ReLU'))\n",
        "model.add(Dense(16, activation='ReLU'))\n",
        "model.add(Dropout(0.1))\n",
        "model.add(Dense(3, activation='softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1735f521-3a11-4722-adf7-ec802bf7da13",
        "id": "cYr0J4_G1wTD"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_77\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " simple_rnn_122 (SimpleRNN)  (None, 20, 256)           66048     \n",
            "                                                                 \n",
            " simple_rnn_123 (SimpleRNN)  (None, 128)               49280     \n",
            "                                                                 \n",
            " dense_98 (Dense)            (None, 64)                8256      \n",
            "                                                                 \n",
            " dropout_31 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_99 (Dense)            (None, 32)                2080      \n",
            "                                                                 \n",
            " dense_100 (Dense)           (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_32 (Dropout)        (None, 16)                0         \n",
            "                                                                 \n",
            " dense_101 (Dense)           (None, 3)                 51        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 126,243\n",
            "Trainable params: 126,243\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# RNN 레이어 1, FC 레이어 1\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델의 실행 옵션\n",
        "# optimizer\n",
        "# adam, sgd,\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adagrad', metrics=['accuracy'])\n",
        "\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "\n",
        "# 모델 저장 조건 설정\n",
        "modelpath = 'RNN_5.hdf5'\n",
        "checkpointer=ModelCheckpoint(filepath=modelpath, monitor='val_loss', verbose=1, save_best_only=True)\n",
        " \n",
        "# 학습 자동 중단 설정\n",
        "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=20)"
      ],
      "metadata": {
        "id": "J62DQ7oJ1wTE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 실행 (양이 많지 않으므로 배치 크기 1)\n",
        "history = model.fit(x_train, y_train, batch_size=1, epochs=100,\n",
        "                    validation_data = (x_test, y_test), callbacks=[checkpointer, early_stopping_callback])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9eaef96d-468a-4eff-cdaf-37de558eba91",
        "id": "S3v4sb9_1wTE"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "160/161 [============================>.] - ETA: 0s - loss: 1.1476 - accuracy: 0.2875\n",
            "Epoch 1: val_loss improved from inf to 1.09742, saving model to RNN_5.hdf5\n",
            "161/161 [==============================] - 4s 14ms/step - loss: 1.1479 - accuracy: 0.2857 - val_loss: 1.0974 - val_accuracy: 0.3415\n",
            "Epoch 2/100\n",
            "157/161 [============================>.] - ETA: 0s - loss: 1.1044 - accuracy: 0.2994\n",
            "Epoch 2: val_loss improved from 1.09742 to 1.07962, saving model to RNN_5.hdf5\n",
            "161/161 [==============================] - 2s 12ms/step - loss: 1.1077 - accuracy: 0.2919 - val_loss: 1.0796 - val_accuracy: 0.3171\n",
            "Epoch 3/100\n",
            "159/161 [============================>.] - ETA: 0s - loss: 1.1041 - accuracy: 0.3145\n",
            "Epoch 3: val_loss improved from 1.07962 to 1.04700, saving model to RNN_5.hdf5\n",
            "161/161 [==============================] - 2s 13ms/step - loss: 1.1053 - accuracy: 0.3106 - val_loss: 1.0470 - val_accuracy: 0.6585\n",
            "Epoch 4/100\n",
            "161/161 [==============================] - ETA: 0s - loss: 1.0706 - accuracy: 0.4472\n",
            "Epoch 4: val_loss improved from 1.04700 to 1.01476, saving model to RNN_5.hdf5\n",
            "161/161 [==============================] - 2s 14ms/step - loss: 1.0706 - accuracy: 0.4472 - val_loss: 1.0148 - val_accuracy: 0.6585\n",
            "Epoch 5/100\n",
            "160/161 [============================>.] - ETA: 0s - loss: 1.0214 - accuracy: 0.5188\n",
            "Epoch 5: val_loss improved from 1.01476 to 0.97345, saving model to RNN_5.hdf5\n",
            "161/161 [==============================] - 3s 20ms/step - loss: 1.0209 - accuracy: 0.5217 - val_loss: 0.9734 - val_accuracy: 0.6585\n",
            "Epoch 6/100\n",
            "160/161 [============================>.] - ETA: 0s - loss: 0.9995 - accuracy: 0.5562\n",
            "Epoch 6: val_loss improved from 0.97345 to 0.91560, saving model to RNN_5.hdf5\n",
            "161/161 [==============================] - 3s 18ms/step - loss: 0.9969 - accuracy: 0.5590 - val_loss: 0.9156 - val_accuracy: 0.6585\n",
            "Epoch 7/100\n",
            "161/161 [==============================] - ETA: 0s - loss: 0.9471 - accuracy: 0.6025\n",
            "Epoch 7: val_loss improved from 0.91560 to 0.88133, saving model to RNN_5.hdf5\n",
            "161/161 [==============================] - 2s 13ms/step - loss: 0.9471 - accuracy: 0.6025 - val_loss: 0.8813 - val_accuracy: 0.6585\n",
            "Epoch 8/100\n",
            "159/161 [============================>.] - ETA: 0s - loss: 0.8928 - accuracy: 0.6164\n",
            "Epoch 8: val_loss improved from 0.88133 to 0.76409, saving model to RNN_5.hdf5\n",
            "161/161 [==============================] - 2s 12ms/step - loss: 0.8893 - accuracy: 0.6211 - val_loss: 0.7641 - val_accuracy: 0.7561\n",
            "Epoch 9/100\n",
            "159/161 [============================>.] - ETA: 0s - loss: 0.8999 - accuracy: 0.5660\n",
            "Epoch 9: val_loss improved from 0.76409 to 0.72561, saving model to RNN_5.hdf5\n",
            "161/161 [==============================] - 2s 12ms/step - loss: 0.8968 - accuracy: 0.5714 - val_loss: 0.7256 - val_accuracy: 0.7073\n",
            "Epoch 10/100\n",
            "160/161 [============================>.] - ETA: 0s - loss: 0.8635 - accuracy: 0.5875\n",
            "Epoch 10: val_loss improved from 0.72561 to 0.69949, saving model to RNN_5.hdf5\n",
            "161/161 [==============================] - 2s 11ms/step - loss: 0.8630 - accuracy: 0.5901 - val_loss: 0.6995 - val_accuracy: 0.7073\n",
            "Epoch 11/100\n",
            "160/161 [============================>.] - ETA: 0s - loss: 0.8246 - accuracy: 0.6000\n",
            "Epoch 11: val_loss improved from 0.69949 to 0.65991, saving model to RNN_5.hdf5\n",
            "161/161 [==============================] - 2s 13ms/step - loss: 0.8221 - accuracy: 0.6025 - val_loss: 0.6599 - val_accuracy: 0.7561\n",
            "Epoch 12/100\n",
            "161/161 [==============================] - ETA: 0s - loss: 0.7793 - accuracy: 0.6460\n",
            "Epoch 12: val_loss did not improve from 0.65991\n",
            "161/161 [==============================] - 2s 13ms/step - loss: 0.7793 - accuracy: 0.6460 - val_loss: 0.6607 - val_accuracy: 0.7073\n",
            "Epoch 13/100\n",
            "158/161 [============================>.] - ETA: 0s - loss: 0.7887 - accuracy: 0.6392\n",
            "Epoch 13: val_loss improved from 0.65991 to 0.62337, saving model to RNN_5.hdf5\n",
            "161/161 [==============================] - 2s 13ms/step - loss: 0.7971 - accuracy: 0.6335 - val_loss: 0.6234 - val_accuracy: 0.7073\n",
            "Epoch 14/100\n",
            "158/161 [============================>.] - ETA: 0s - loss: 0.7681 - accuracy: 0.6646\n",
            "Epoch 14: val_loss improved from 0.62337 to 0.59924, saving model to RNN_5.hdf5\n",
            "161/161 [==============================] - 2s 11ms/step - loss: 0.7594 - accuracy: 0.6708 - val_loss: 0.5992 - val_accuracy: 0.7561\n",
            "Epoch 15/100\n",
            "159/161 [============================>.] - ETA: 0s - loss: 0.7592 - accuracy: 0.6667\n",
            "Epoch 15: val_loss did not improve from 0.59924\n",
            "161/161 [==============================] - 2s 11ms/step - loss: 0.7653 - accuracy: 0.6646 - val_loss: 0.6569 - val_accuracy: 0.6829\n",
            "Epoch 16/100\n",
            "159/161 [============================>.] - ETA: 0s - loss: 0.7531 - accuracy: 0.6604\n",
            "Epoch 16: val_loss improved from 0.59924 to 0.57756, saving model to RNN_5.hdf5\n",
            "161/161 [==============================] - 2s 12ms/step - loss: 0.7478 - accuracy: 0.6646 - val_loss: 0.5776 - val_accuracy: 0.7317\n",
            "Epoch 17/100\n",
            "158/161 [============================>.] - ETA: 0s - loss: 0.7270 - accuracy: 0.6392\n",
            "Epoch 17: val_loss improved from 0.57756 to 0.57462, saving model to RNN_5.hdf5\n",
            "161/161 [==============================] - 2s 12ms/step - loss: 0.7383 - accuracy: 0.6335 - val_loss: 0.5746 - val_accuracy: 0.7805\n",
            "Epoch 18/100\n",
            "158/161 [============================>.] - ETA: 0s - loss: 0.7490 - accuracy: 0.6582\n",
            "Epoch 18: val_loss did not improve from 0.57462\n",
            "161/161 [==============================] - 2s 11ms/step - loss: 0.7550 - accuracy: 0.6584 - val_loss: 0.5892 - val_accuracy: 0.7073\n",
            "Epoch 19/100\n",
            "160/161 [============================>.] - ETA: 0s - loss: 0.7659 - accuracy: 0.6500\n",
            "Epoch 19: val_loss improved from 0.57462 to 0.57006, saving model to RNN_5.hdf5\n",
            "161/161 [==============================] - 2s 11ms/step - loss: 0.7618 - accuracy: 0.6522 - val_loss: 0.5701 - val_accuracy: 0.8049\n",
            "Epoch 20/100\n",
            "161/161 [==============================] - ETA: 0s - loss: 0.7326 - accuracy: 0.6584\n",
            "Epoch 20: val_loss improved from 0.57006 to 0.55793, saving model to RNN_5.hdf5\n",
            "161/161 [==============================] - 2s 11ms/step - loss: 0.7326 - accuracy: 0.6584 - val_loss: 0.5579 - val_accuracy: 0.8293\n",
            "Epoch 21/100\n",
            "160/161 [============================>.] - ETA: 0s - loss: 0.7372 - accuracy: 0.6375\n",
            "Epoch 21: val_loss improved from 0.55793 to 0.54161, saving model to RNN_5.hdf5\n",
            "161/161 [==============================] - 2s 11ms/step - loss: 0.7339 - accuracy: 0.6398 - val_loss: 0.5416 - val_accuracy: 0.7805\n",
            "Epoch 22/100\n",
            "156/161 [============================>.] - ETA: 0s - loss: 0.7413 - accuracy: 0.5833\n",
            "Epoch 22: val_loss did not improve from 0.54161\n",
            "161/161 [==============================] - 2s 12ms/step - loss: 0.7299 - accuracy: 0.5901 - val_loss: 0.5596 - val_accuracy: 0.7561\n",
            "Epoch 23/100\n",
            "161/161 [==============================] - ETA: 0s - loss: 0.7161 - accuracy: 0.6522\n",
            "Epoch 23: val_loss did not improve from 0.54161\n",
            "161/161 [==============================] - 2s 11ms/step - loss: 0.7161 - accuracy: 0.6522 - val_loss: 0.5480 - val_accuracy: 0.7561\n",
            "Epoch 24/100\n",
            "161/161 [==============================] - ETA: 0s - loss: 0.7483 - accuracy: 0.6460\n",
            "Epoch 24: val_loss improved from 0.54161 to 0.53886, saving model to RNN_5.hdf5\n",
            "161/161 [==============================] - 2s 12ms/step - loss: 0.7483 - accuracy: 0.6460 - val_loss: 0.5389 - val_accuracy: 0.7317\n",
            "Epoch 25/100\n",
            "157/161 [============================>.] - ETA: 0s - loss: 0.7088 - accuracy: 0.6561\n",
            "Epoch 25: val_loss did not improve from 0.53886\n",
            "161/161 [==============================] - 2s 12ms/step - loss: 0.7068 - accuracy: 0.6646 - val_loss: 0.5705 - val_accuracy: 0.6829\n",
            "Epoch 26/100\n",
            "160/161 [============================>.] - ETA: 0s - loss: 0.7123 - accuracy: 0.6875\n",
            "Epoch 26: val_loss did not improve from 0.53886\n",
            "161/161 [==============================] - 3s 20ms/step - loss: 0.7112 - accuracy: 0.6894 - val_loss: 0.5615 - val_accuracy: 0.7073\n",
            "Epoch 27/100\n",
            "158/161 [============================>.] - ETA: 0s - loss: 0.7214 - accuracy: 0.6519\n",
            "Epoch 27: val_loss did not improve from 0.53886\n",
            "161/161 [==============================] - 2s 12ms/step - loss: 0.7171 - accuracy: 0.6584 - val_loss: 0.5399 - val_accuracy: 0.7561\n",
            "Epoch 28/100\n",
            "160/161 [============================>.] - ETA: 0s - loss: 0.6463 - accuracy: 0.6687\n",
            "Epoch 28: val_loss improved from 0.53886 to 0.51425, saving model to RNN_5.hdf5\n",
            "161/161 [==============================] - 2s 11ms/step - loss: 0.6498 - accuracy: 0.6646 - val_loss: 0.5142 - val_accuracy: 0.7561\n",
            "Epoch 29/100\n",
            "157/161 [============================>.] - ETA: 0s - loss: 0.6962 - accuracy: 0.6178\n",
            "Epoch 29: val_loss did not improve from 0.51425\n",
            "161/161 [==============================] - 2s 11ms/step - loss: 0.7155 - accuracy: 0.6087 - val_loss: 0.5254 - val_accuracy: 0.7317\n",
            "Epoch 30/100\n",
            "158/161 [============================>.] - ETA: 0s - loss: 0.6981 - accuracy: 0.6519\n",
            "Epoch 30: val_loss did not improve from 0.51425\n",
            "161/161 [==============================] - 2s 12ms/step - loss: 0.6905 - accuracy: 0.6584 - val_loss: 0.5544 - val_accuracy: 0.7073\n",
            "Epoch 31/100\n",
            "157/161 [============================>.] - ETA: 0s - loss: 0.6926 - accuracy: 0.6879\n",
            "Epoch 31: val_loss did not improve from 0.51425\n",
            "161/161 [==============================] - 2s 11ms/step - loss: 0.6892 - accuracy: 0.6957 - val_loss: 0.5353 - val_accuracy: 0.7561\n",
            "Epoch 32/100\n",
            "160/161 [============================>.] - ETA: 0s - loss: 0.7338 - accuracy: 0.6313\n",
            "Epoch 32: val_loss did not improve from 0.51425\n",
            "161/161 [==============================] - 2s 12ms/step - loss: 0.7307 - accuracy: 0.6335 - val_loss: 0.5241 - val_accuracy: 0.7561\n",
            "Epoch 33/100\n",
            "159/161 [============================>.] - ETA: 0s - loss: 0.6826 - accuracy: 0.6478\n",
            "Epoch 33: val_loss did not improve from 0.51425\n",
            "161/161 [==============================] - 2s 11ms/step - loss: 0.6923 - accuracy: 0.6460 - val_loss: 0.5256 - val_accuracy: 0.7561\n",
            "Epoch 34/100\n",
            "160/161 [============================>.] - ETA: 0s - loss: 0.6967 - accuracy: 0.6500\n",
            "Epoch 34: val_loss did not improve from 0.51425\n",
            "161/161 [==============================] - 2s 11ms/step - loss: 0.6945 - accuracy: 0.6522 - val_loss: 0.5386 - val_accuracy: 0.7317\n",
            "Epoch 35/100\n",
            "159/161 [============================>.] - ETA: 0s - loss: 0.6879 - accuracy: 0.6604\n",
            "Epoch 35: val_loss did not improve from 0.51425\n",
            "161/161 [==============================] - 2s 11ms/step - loss: 0.6948 - accuracy: 0.6584 - val_loss: 0.5377 - val_accuracy: 0.7561\n",
            "Epoch 36/100\n",
            "161/161 [==============================] - ETA: 0s - loss: 0.6641 - accuracy: 0.6894\n",
            "Epoch 36: val_loss improved from 0.51425 to 0.50483, saving model to RNN_5.hdf5\n",
            "161/161 [==============================] - 2s 13ms/step - loss: 0.6641 - accuracy: 0.6894 - val_loss: 0.5048 - val_accuracy: 0.8049\n",
            "Epoch 37/100\n",
            "160/161 [============================>.] - ETA: 0s - loss: 0.6902 - accuracy: 0.6625\n",
            "Epoch 37: val_loss did not improve from 0.50483\n",
            "161/161 [==============================] - 2s 12ms/step - loss: 0.6870 - accuracy: 0.6646 - val_loss: 0.5755 - val_accuracy: 0.6829\n",
            "Epoch 38/100\n",
            "158/161 [============================>.] - ETA: 0s - loss: 0.6715 - accuracy: 0.6772\n",
            "Epoch 38: val_loss did not improve from 0.50483\n",
            "161/161 [==============================] - 2s 12ms/step - loss: 0.6843 - accuracy: 0.6770 - val_loss: 0.5237 - val_accuracy: 0.7561\n",
            "Epoch 39/100\n",
            "160/161 [============================>.] - ETA: 0s - loss: 0.6699 - accuracy: 0.6750\n",
            "Epoch 39: val_loss improved from 0.50483 to 0.49960, saving model to RNN_5.hdf5\n",
            "161/161 [==============================] - 2s 14ms/step - loss: 0.6681 - accuracy: 0.6770 - val_loss: 0.4996 - val_accuracy: 0.8049\n",
            "Epoch 40/100\n",
            "156/161 [============================>.] - ETA: 0s - loss: 0.7260 - accuracy: 0.6410\n",
            "Epoch 40: val_loss did not improve from 0.49960\n",
            "161/161 [==============================] - 2s 11ms/step - loss: 0.7163 - accuracy: 0.6398 - val_loss: 0.5188 - val_accuracy: 0.7561\n",
            "Epoch 41/100\n",
            "157/161 [============================>.] - ETA: 0s - loss: 0.6687 - accuracy: 0.7006\n",
            "Epoch 41: val_loss did not improve from 0.49960\n",
            "161/161 [==============================] - 2s 11ms/step - loss: 0.6719 - accuracy: 0.6957 - val_loss: 0.5116 - val_accuracy: 0.7561\n",
            "Epoch 42/100\n",
            "160/161 [============================>.] - ETA: 0s - loss: 0.6611 - accuracy: 0.6438\n",
            "Epoch 42: val_loss did not improve from 0.49960\n",
            "161/161 [==============================] - 2s 11ms/step - loss: 0.6596 - accuracy: 0.6460 - val_loss: 0.5290 - val_accuracy: 0.7561\n",
            "Epoch 43/100\n",
            "160/161 [============================>.] - ETA: 0s - loss: 0.6687 - accuracy: 0.6500\n",
            "Epoch 43: val_loss did not improve from 0.49960\n",
            "161/161 [==============================] - 2s 12ms/step - loss: 0.6685 - accuracy: 0.6522 - val_loss: 0.5147 - val_accuracy: 0.7561\n",
            "Epoch 44/100\n",
            "159/161 [============================>.] - ETA: 0s - loss: 0.6689 - accuracy: 0.6415\n",
            "Epoch 44: val_loss improved from 0.49960 to 0.49917, saving model to RNN_5.hdf5\n",
            "161/161 [==============================] - 2s 12ms/step - loss: 0.6696 - accuracy: 0.6460 - val_loss: 0.4992 - val_accuracy: 0.7561\n",
            "Epoch 45/100\n",
            "158/161 [============================>.] - ETA: 0s - loss: 0.6620 - accuracy: 0.7089\n",
            "Epoch 45: val_loss improved from 0.49917 to 0.49155, saving model to RNN_5.hdf5\n",
            "161/161 [==============================] - 2s 14ms/step - loss: 0.6587 - accuracy: 0.7143 - val_loss: 0.4916 - val_accuracy: 0.7561\n",
            "Epoch 46/100\n",
            "159/161 [============================>.] - ETA: 0s - loss: 0.6601 - accuracy: 0.7044\n",
            "Epoch 46: val_loss improved from 0.49155 to 0.49062, saving model to RNN_5.hdf5\n",
            "161/161 [==============================] - 2s 13ms/step - loss: 0.6580 - accuracy: 0.7081 - val_loss: 0.4906 - val_accuracy: 0.8049\n",
            "Epoch 47/100\n",
            "160/161 [============================>.] - ETA: 0s - loss: 0.6929 - accuracy: 0.6313\n",
            "Epoch 47: val_loss did not improve from 0.49062\n",
            "161/161 [==============================] - 3s 19ms/step - loss: 0.6953 - accuracy: 0.6273 - val_loss: 0.5093 - val_accuracy: 0.7561\n",
            "Epoch 48/100\n",
            "158/161 [============================>.] - ETA: 0s - loss: 0.6730 - accuracy: 0.6519\n",
            "Epoch 48: val_loss improved from 0.49062 to 0.48279, saving model to RNN_5.hdf5\n",
            "161/161 [==============================] - 2s 15ms/step - loss: 0.6882 - accuracy: 0.6522 - val_loss: 0.4828 - val_accuracy: 0.7561\n",
            "Epoch 49/100\n",
            "160/161 [============================>.] - ETA: 0s - loss: 0.7085 - accuracy: 0.6438\n",
            "Epoch 49: val_loss did not improve from 0.48279\n",
            "161/161 [==============================] - 2s 13ms/step - loss: 0.7068 - accuracy: 0.6460 - val_loss: 0.4832 - val_accuracy: 0.7317\n",
            "Epoch 50/100\n",
            "158/161 [============================>.] - ETA: 0s - loss: 0.6517 - accuracy: 0.7025\n",
            "Epoch 50: val_loss improved from 0.48279 to 0.48032, saving model to RNN_5.hdf5\n",
            "161/161 [==============================] - 2s 13ms/step - loss: 0.6498 - accuracy: 0.7019 - val_loss: 0.4803 - val_accuracy: 0.7805\n",
            "Epoch 51/100\n",
            "160/161 [============================>.] - ETA: 0s - loss: 0.6226 - accuracy: 0.7125\n",
            "Epoch 51: val_loss did not improve from 0.48032\n",
            "161/161 [==============================] - 2s 11ms/step - loss: 0.6293 - accuracy: 0.7081 - val_loss: 0.5753 - val_accuracy: 0.7073\n",
            "Epoch 52/100\n",
            "161/161 [==============================] - ETA: 0s - loss: 0.6796 - accuracy: 0.6398\n",
            "Epoch 52: val_loss did not improve from 0.48032\n",
            "161/161 [==============================] - 2s 12ms/step - loss: 0.6796 - accuracy: 0.6398 - val_loss: 0.5810 - val_accuracy: 0.7561\n",
            "Epoch 53/100\n",
            "158/161 [============================>.] - ETA: 0s - loss: 0.7235 - accuracy: 0.6013\n",
            "Epoch 53: val_loss improved from 0.48032 to 0.47837, saving model to RNN_5.hdf5\n",
            "161/161 [==============================] - 2s 13ms/step - loss: 0.7154 - accuracy: 0.6087 - val_loss: 0.4784 - val_accuracy: 0.8293\n",
            "Epoch 54/100\n",
            "159/161 [============================>.] - ETA: 0s - loss: 0.6461 - accuracy: 0.6792\n",
            "Epoch 54: val_loss did not improve from 0.47837\n",
            "161/161 [==============================] - 2s 13ms/step - loss: 0.6383 - accuracy: 0.6832 - val_loss: 0.4912 - val_accuracy: 0.7561\n",
            "Epoch 55/100\n",
            "161/161 [==============================] - ETA: 0s - loss: 0.6442 - accuracy: 0.6708\n",
            "Epoch 55: val_loss did not improve from 0.47837\n",
            "161/161 [==============================] - 2s 13ms/step - loss: 0.6442 - accuracy: 0.6708 - val_loss: 0.4943 - val_accuracy: 0.7805\n",
            "Epoch 56/100\n",
            "157/161 [============================>.] - ETA: 0s - loss: 0.6224 - accuracy: 0.7325\n",
            "Epoch 56: val_loss improved from 0.47837 to 0.47703, saving model to RNN_5.hdf5\n",
            "161/161 [==============================] - 2s 12ms/step - loss: 0.6350 - accuracy: 0.7267 - val_loss: 0.4770 - val_accuracy: 0.8049\n",
            "Epoch 57/100\n",
            "157/161 [============================>.] - ETA: 0s - loss: 0.6334 - accuracy: 0.7134\n",
            "Epoch 57: val_loss improved from 0.47703 to 0.47676, saving model to RNN_5.hdf5\n",
            "161/161 [==============================] - 2s 13ms/step - loss: 0.6462 - accuracy: 0.7019 - val_loss: 0.4768 - val_accuracy: 0.7805\n",
            "Epoch 58/100\n",
            "156/161 [============================>.] - ETA: 0s - loss: 0.6389 - accuracy: 0.6218\n",
            "Epoch 58: val_loss did not improve from 0.47676\n",
            "161/161 [==============================] - 2s 13ms/step - loss: 0.6518 - accuracy: 0.6211 - val_loss: 0.4835 - val_accuracy: 0.7561\n",
            "Epoch 59/100\n",
            "161/161 [==============================] - ETA: 0s - loss: 0.6079 - accuracy: 0.7081\n",
            "Epoch 59: val_loss improved from 0.47676 to 0.46382, saving model to RNN_5.hdf5\n",
            "161/161 [==============================] - 2s 12ms/step - loss: 0.6079 - accuracy: 0.7081 - val_loss: 0.4638 - val_accuracy: 0.7805\n",
            "Epoch 60/100\n",
            "159/161 [============================>.] - ETA: 0s - loss: 0.6775 - accuracy: 0.6981\n",
            "Epoch 60: val_loss did not improve from 0.46382\n",
            "161/161 [==============================] - 2s 13ms/step - loss: 0.6741 - accuracy: 0.6957 - val_loss: 0.4737 - val_accuracy: 0.8049\n",
            "Epoch 61/100\n",
            "159/161 [============================>.] - ETA: 0s - loss: 0.6374 - accuracy: 0.6604\n",
            "Epoch 61: val_loss did not improve from 0.46382\n",
            "161/161 [==============================] - 2s 12ms/step - loss: 0.6416 - accuracy: 0.6522 - val_loss: 0.5324 - val_accuracy: 0.7561\n",
            "Epoch 62/100\n",
            "161/161 [==============================] - ETA: 0s - loss: 0.6447 - accuracy: 0.6708\n",
            "Epoch 62: val_loss improved from 0.46382 to 0.46055, saving model to RNN_5.hdf5\n",
            "161/161 [==============================] - 2s 11ms/step - loss: 0.6447 - accuracy: 0.6708 - val_loss: 0.4606 - val_accuracy: 0.7561\n",
            "Epoch 63/100\n",
            "160/161 [============================>.] - ETA: 0s - loss: 0.6254 - accuracy: 0.6938\n",
            "Epoch 63: val_loss did not improve from 0.46055\n",
            "161/161 [==============================] - 2s 12ms/step - loss: 0.6317 - accuracy: 0.6894 - val_loss: 0.4660 - val_accuracy: 0.8293\n",
            "Epoch 64/100\n",
            "161/161 [==============================] - ETA: 0s - loss: 0.6846 - accuracy: 0.6398\n",
            "Epoch 64: val_loss did not improve from 0.46055\n",
            "161/161 [==============================] - 2s 12ms/step - loss: 0.6846 - accuracy: 0.6398 - val_loss: 0.5286 - val_accuracy: 0.7561\n",
            "Epoch 65/100\n",
            "159/161 [============================>.] - ETA: 0s - loss: 0.6575 - accuracy: 0.6730\n",
            "Epoch 65: val_loss did not improve from 0.46055\n",
            "161/161 [==============================] - 2s 11ms/step - loss: 0.6508 - accuracy: 0.6770 - val_loss: 0.4653 - val_accuracy: 0.8293\n",
            "Epoch 66/100\n",
            "160/161 [============================>.] - ETA: 0s - loss: 0.6537 - accuracy: 0.6875\n",
            "Epoch 66: val_loss did not improve from 0.46055\n",
            "161/161 [==============================] - 2s 11ms/step - loss: 0.6638 - accuracy: 0.6832 - val_loss: 0.4720 - val_accuracy: 0.8049\n",
            "Epoch 67/100\n",
            "161/161 [==============================] - ETA: 0s - loss: 0.6773 - accuracy: 0.6832\n",
            "Epoch 67: val_loss did not improve from 0.46055\n",
            "161/161 [==============================] - 2s 14ms/step - loss: 0.6773 - accuracy: 0.6832 - val_loss: 0.4782 - val_accuracy: 0.7805\n",
            "Epoch 68/100\n",
            "161/161 [==============================] - ETA: 0s - loss: 0.6422 - accuracy: 0.6708\n",
            "Epoch 68: val_loss did not improve from 0.46055\n",
            "161/161 [==============================] - 3s 17ms/step - loss: 0.6422 - accuracy: 0.6708 - val_loss: 0.4841 - val_accuracy: 0.7805\n",
            "Epoch 69/100\n",
            "157/161 [============================>.] - ETA: 0s - loss: 0.6060 - accuracy: 0.6879\n",
            "Epoch 69: val_loss did not improve from 0.46055\n",
            "161/161 [==============================] - 2s 14ms/step - loss: 0.6030 - accuracy: 0.6894 - val_loss: 0.4778 - val_accuracy: 0.7805\n",
            "Epoch 70/100\n",
            "157/161 [============================>.] - ETA: 0s - loss: 0.6218 - accuracy: 0.6688\n",
            "Epoch 70: val_loss did not improve from 0.46055\n",
            "161/161 [==============================] - 2s 11ms/step - loss: 0.6384 - accuracy: 0.6646 - val_loss: 0.5416 - val_accuracy: 0.7561\n",
            "Epoch 71/100\n",
            "159/161 [============================>.] - ETA: 0s - loss: 0.6279 - accuracy: 0.6918\n",
            "Epoch 71: val_loss improved from 0.46055 to 0.44982, saving model to RNN_5.hdf5\n",
            "161/161 [==============================] - 2s 12ms/step - loss: 0.6255 - accuracy: 0.6957 - val_loss: 0.4498 - val_accuracy: 0.8049\n",
            "Epoch 72/100\n",
            "159/161 [============================>.] - ETA: 0s - loss: 0.6352 - accuracy: 0.6541\n",
            "Epoch 72: val_loss did not improve from 0.44982\n",
            "161/161 [==============================] - 2s 14ms/step - loss: 0.6376 - accuracy: 0.6522 - val_loss: 0.4560 - val_accuracy: 0.8293\n",
            "Epoch 73/100\n",
            "159/161 [============================>.] - ETA: 0s - loss: 0.6260 - accuracy: 0.7233\n",
            "Epoch 73: val_loss did not improve from 0.44982\n",
            "161/161 [==============================] - 2s 13ms/step - loss: 0.6207 - accuracy: 0.7267 - val_loss: 0.4541 - val_accuracy: 0.8293\n",
            "Epoch 74/100\n",
            "160/161 [============================>.] - ETA: 0s - loss: 0.6392 - accuracy: 0.6687\n",
            "Epoch 74: val_loss did not improve from 0.44982\n",
            "161/161 [==============================] - 2s 11ms/step - loss: 0.6352 - accuracy: 0.6708 - val_loss: 0.4559 - val_accuracy: 0.8293\n",
            "Epoch 75/100\n",
            "157/161 [============================>.] - ETA: 0s - loss: 0.5931 - accuracy: 0.7389\n",
            "Epoch 75: val_loss did not improve from 0.44982\n",
            "161/161 [==============================] - 2s 13ms/step - loss: 0.6090 - accuracy: 0.7329 - val_loss: 0.4925 - val_accuracy: 0.7805\n",
            "Epoch 76/100\n",
            "161/161 [==============================] - ETA: 0s - loss: 0.6225 - accuracy: 0.6957\n",
            "Epoch 76: val_loss did not improve from 0.44982\n",
            "161/161 [==============================] - 2s 11ms/step - loss: 0.6225 - accuracy: 0.6957 - val_loss: 0.4592 - val_accuracy: 0.8293\n",
            "Epoch 77/100\n",
            "158/161 [============================>.] - ETA: 0s - loss: 0.6015 - accuracy: 0.7152\n",
            "Epoch 77: val_loss did not improve from 0.44982\n",
            "161/161 [==============================] - 2s 11ms/step - loss: 0.6186 - accuracy: 0.7081 - val_loss: 0.4628 - val_accuracy: 0.8049\n",
            "Epoch 78/100\n",
            "161/161 [==============================] - ETA: 0s - loss: 0.6012 - accuracy: 0.7019\n",
            "Epoch 78: val_loss did not improve from 0.44982\n",
            "161/161 [==============================] - 2s 12ms/step - loss: 0.6012 - accuracy: 0.7019 - val_loss: 0.4572 - val_accuracy: 0.8049\n",
            "Epoch 79/100\n",
            "161/161 [==============================] - ETA: 0s - loss: 0.6202 - accuracy: 0.7081\n",
            "Epoch 79: val_loss improved from 0.44982 to 0.44603, saving model to RNN_5.hdf5\n",
            "161/161 [==============================] - 2s 11ms/step - loss: 0.6202 - accuracy: 0.7081 - val_loss: 0.4460 - val_accuracy: 0.8049\n",
            "Epoch 80/100\n",
            "158/161 [============================>.] - ETA: 0s - loss: 0.5932 - accuracy: 0.7089\n",
            "Epoch 80: val_loss did not improve from 0.44603\n",
            "161/161 [==============================] - 2s 11ms/step - loss: 0.6137 - accuracy: 0.7019 - val_loss: 0.4601 - val_accuracy: 0.8293\n",
            "Epoch 81/100\n",
            "158/161 [============================>.] - ETA: 0s - loss: 0.6002 - accuracy: 0.7089\n",
            "Epoch 81: val_loss did not improve from 0.44603\n",
            "161/161 [==============================] - 2s 11ms/step - loss: 0.5977 - accuracy: 0.7081 - val_loss: 0.4782 - val_accuracy: 0.8293\n",
            "Epoch 82/100\n",
            "161/161 [==============================] - ETA: 0s - loss: 0.6050 - accuracy: 0.7205\n",
            "Epoch 82: val_loss did not improve from 0.44603\n",
            "161/161 [==============================] - 2s 11ms/step - loss: 0.6050 - accuracy: 0.7205 - val_loss: 0.4548 - val_accuracy: 0.8537\n",
            "Epoch 83/100\n",
            "157/161 [============================>.] - ETA: 0s - loss: 0.5619 - accuracy: 0.7070\n",
            "Epoch 83: val_loss did not improve from 0.44603\n",
            "161/161 [==============================] - 2s 11ms/step - loss: 0.5746 - accuracy: 0.7019 - val_loss: 0.5245 - val_accuracy: 0.7317\n",
            "Epoch 84/100\n",
            "161/161 [==============================] - ETA: 0s - loss: 0.6463 - accuracy: 0.6646\n",
            "Epoch 84: val_loss did not improve from 0.44603\n",
            "161/161 [==============================] - 2s 12ms/step - loss: 0.6463 - accuracy: 0.6646 - val_loss: 0.4823 - val_accuracy: 0.7805\n",
            "Epoch 85/100\n",
            "156/161 [============================>.] - ETA: 0s - loss: 0.6188 - accuracy: 0.7308\n",
            "Epoch 85: val_loss did not improve from 0.44603\n",
            "161/161 [==============================] - 2s 10ms/step - loss: 0.6132 - accuracy: 0.7329 - val_loss: 0.4525 - val_accuracy: 0.7805\n",
            "Epoch 86/100\n",
            "159/161 [============================>.] - ETA: 0s - loss: 0.5880 - accuracy: 0.7296\n",
            "Epoch 86: val_loss improved from 0.44603 to 0.43936, saving model to RNN_5.hdf5\n",
            "161/161 [==============================] - 2s 11ms/step - loss: 0.5868 - accuracy: 0.7267 - val_loss: 0.4394 - val_accuracy: 0.8293\n",
            "Epoch 87/100\n",
            "160/161 [============================>.] - ETA: 0s - loss: 0.6176 - accuracy: 0.7375\n",
            "Epoch 87: val_loss did not improve from 0.43936\n",
            "161/161 [==============================] - 2s 12ms/step - loss: 0.6139 - accuracy: 0.7391 - val_loss: 0.4458 - val_accuracy: 0.8537\n",
            "Epoch 88/100\n",
            "161/161 [==============================] - ETA: 0s - loss: 0.6180 - accuracy: 0.7453\n",
            "Epoch 88: val_loss did not improve from 0.43936\n",
            "161/161 [==============================] - 2s 14ms/step - loss: 0.6180 - accuracy: 0.7453 - val_loss: 0.4486 - val_accuracy: 0.8293\n",
            "Epoch 89/100\n",
            "161/161 [==============================] - ETA: 0s - loss: 0.5921 - accuracy: 0.7143\n",
            "Epoch 89: val_loss did not improve from 0.43936\n",
            "161/161 [==============================] - 3s 16ms/step - loss: 0.5921 - accuracy: 0.7143 - val_loss: 0.4395 - val_accuracy: 0.8293\n",
            "Epoch 90/100\n",
            "161/161 [==============================] - ETA: 0s - loss: 0.6429 - accuracy: 0.6646\n",
            "Epoch 90: val_loss improved from 0.43936 to 0.43847, saving model to RNN_5.hdf5\n",
            "161/161 [==============================] - 2s 11ms/step - loss: 0.6429 - accuracy: 0.6646 - val_loss: 0.4385 - val_accuracy: 0.8293\n",
            "Epoch 91/100\n",
            "159/161 [============================>.] - ETA: 0s - loss: 0.5901 - accuracy: 0.7044\n",
            "Epoch 91: val_loss did not improve from 0.43847\n",
            "161/161 [==============================] - 2s 12ms/step - loss: 0.5999 - accuracy: 0.6957 - val_loss: 0.4553 - val_accuracy: 0.8293\n",
            "Epoch 92/100\n",
            "160/161 [============================>.] - ETA: 0s - loss: 0.5728 - accuracy: 0.7312\n",
            "Epoch 92: val_loss did not improve from 0.43847\n",
            "161/161 [==============================] - 3s 17ms/step - loss: 0.5710 - accuracy: 0.7329 - val_loss: 0.4690 - val_accuracy: 0.8293\n",
            "Epoch 93/100\n",
            "158/161 [============================>.] - ETA: 0s - loss: 0.6102 - accuracy: 0.7342\n",
            "Epoch 93: val_loss did not improve from 0.43847\n",
            "161/161 [==============================] - 2s 12ms/step - loss: 0.6052 - accuracy: 0.7329 - val_loss: 0.4476 - val_accuracy: 0.8293\n",
            "Epoch 94/100\n",
            "161/161 [==============================] - ETA: 0s - loss: 0.5863 - accuracy: 0.7329\n",
            "Epoch 94: val_loss improved from 0.43847 to 0.43341, saving model to RNN_5.hdf5\n",
            "161/161 [==============================] - 2s 12ms/step - loss: 0.5863 - accuracy: 0.7329 - val_loss: 0.4334 - val_accuracy: 0.8537\n",
            "Epoch 95/100\n",
            "161/161 [==============================] - ETA: 0s - loss: 0.6443 - accuracy: 0.6957\n",
            "Epoch 95: val_loss did not improve from 0.43341\n",
            "161/161 [==============================] - 2s 11ms/step - loss: 0.6443 - accuracy: 0.6957 - val_loss: 0.4345 - val_accuracy: 0.8537\n",
            "Epoch 96/100\n",
            "159/161 [============================>.] - ETA: 0s - loss: 0.6106 - accuracy: 0.6918\n",
            "Epoch 96: val_loss did not improve from 0.43341\n",
            "161/161 [==============================] - 2s 13ms/step - loss: 0.6113 - accuracy: 0.6894 - val_loss: 0.4344 - val_accuracy: 0.8537\n",
            "Epoch 97/100\n",
            "161/161 [==============================] - ETA: 0s - loss: 0.6245 - accuracy: 0.6894\n",
            "Epoch 97: val_loss improved from 0.43341 to 0.43088, saving model to RNN_5.hdf5\n",
            "161/161 [==============================] - 2s 14ms/step - loss: 0.6245 - accuracy: 0.6894 - val_loss: 0.4309 - val_accuracy: 0.8293\n",
            "Epoch 98/100\n",
            "160/161 [============================>.] - ETA: 0s - loss: 0.6131 - accuracy: 0.7563\n",
            "Epoch 98: val_loss improved from 0.43088 to 0.43017, saving model to RNN_5.hdf5\n",
            "161/161 [==============================] - 2s 12ms/step - loss: 0.6133 - accuracy: 0.7578 - val_loss: 0.4302 - val_accuracy: 0.8293\n",
            "Epoch 99/100\n",
            "161/161 [==============================] - ETA: 0s - loss: 0.5894 - accuracy: 0.7143\n",
            "Epoch 99: val_loss did not improve from 0.43017\n",
            "161/161 [==============================] - 2s 13ms/step - loss: 0.5894 - accuracy: 0.7143 - val_loss: 0.4334 - val_accuracy: 0.8293\n",
            "Epoch 100/100\n",
            "160/161 [============================>.] - ETA: 0s - loss: 0.5743 - accuracy: 0.7125\n",
            "Epoch 100: val_loss improved from 0.43017 to 0.42255, saving model to RNN_5.hdf5\n",
            "161/161 [==============================] - 2s 11ms/step - loss: 0.5709 - accuracy: 0.7143 - val_loss: 0.4225 - val_accuracy: 0.8293\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "O_FGmXpQ-YLj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![image.png](data:image/png;base64,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)"
      ],
      "metadata": {
        "id": "Cm9P-i0G5Kl-"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "64FKVBiP-XKd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}